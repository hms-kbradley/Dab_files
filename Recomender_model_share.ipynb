{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d21cf39-b1ab-415d-bbaf-31c293c1fdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d3d61c-2a63-4c5d-b35a-65c6c2166911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from Google Sheets\n",
    "url = \"https://docs.google.com/spreadsheets/d/1iDsbDwcxj5nygYZASAIIlY7Jo58tzrxK4qc4Xemj6vU/gviz/tq?tqx=out:csv&gid=465338724\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "Name_input = 'Kevin Bradley'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abc10641-1c32-4328-af45-9a954de38036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "label_encoder = LabelEncoder()\n",
    "data['Reccomended_Type_Encoded'] = label_encoder.fit_transform(data['Reccomended_Type'])\n",
    "\n",
    "features = data[['Reccomended_Type_Encoded', 'Travel_steve_mountains', 'Cancun_rating', 'Egypt_ranking',\n",
    "                 'Atlanta_ranking', 'Tahiti_ranking', 'Grand_Canyon_ranking', 'Tools_tableau',\n",
    "                 'Tools_PowerBI', 'Tools_Python', 'Tools_R', 'Tools_Excel',\n",
    "                 'Tools_GSheets', 'Rate the following movie genres [Science Fiction]', 'Rate the following movie genres [Drama]',\n",
    "                 'Rate the following movie genres [Comedy]', 'Rate the following movie genres [Horror]',\n",
    "                 'Rate the following movie genres [Action]', 'Rate the following movie genres [Epic]', 'Rate the following movie genres [Fantasy]']]\n",
    "target = data['Reccomended_Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13849487-40e4-4f7d-beef-9e5bb39e0aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features_imputed)\n",
    "\n",
    "# Train Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(features_standardized, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "468f801e-a81c-43b9-9f87-ed8977b52e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Person's data\n",
    "person_data = data[data['Name'] == Name_input]\n",
    "X_person_standardized = scaler.transform(imputer.transform(person_data[['Reccomended_Type_Encoded', 'Travel_steve_mountains', \n",
    "                                                                        'Cancun_rating', 'Egypt_ranking',\n",
    "                                       'Atlanta_ranking', 'Tahiti_ranking', 'Grand_Canyon_ranking',\n",
    "                                       'Tools_tableau', 'Tools_PowerBI', 'Tools_Python', 'Tools_R', 'Tools_Excel',\n",
    "                                       'Tools_GSheets', 'Rate the following movie genres [Science Fiction]', \n",
    "                                       'Rate the following movie genres [Drama]', 'Rate the following movie genres [Comedy]',\n",
    "                                       'Rate the following movie genres [Horror]', 'Rate the following movie genres [Action]',\n",
    "                                       'Rate the following movie genres [Epic]', 'Rate the following movie genres [Fantasy]']]))\n",
    "\n",
    "# Predict probabilities\n",
    "proba_person = rf_model.predict_proba(X_person_standardized)\n",
    "\n",
    "# Output top 5 recommendations for Person\n",
    "recommended_titles = target.unique()\n",
    "top_5_indices = np.argsort(proba_person[0])[-5:][::-1]\n",
    "top_5_titles = recommended_titles[top_5_indices]\n",
    "\n",
    "# Feature Importance\n",
    "importance_vals = rf_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': importance_vals}).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001e83c3-e780-4188-a642-ffe001def8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on the whole dataset to calculate accuracy and F1 score\n",
    "predictions = rf_model.predict(features_standardized)\n",
    "\n",
    "person_recommended_type = label_encoder.inverse_transform([person_data['Reccomended_Type_Encoded'].values[0]])[0]\n",
    "\n",
    "# Calculate accuracy and F1 score\n",
    "accuracy = accuracy_score(target, predictions)\n",
    "f1 = f1_score(target, predictions, average='weighted')  # Use weighted average for multi-class classification\n",
    "\n",
    "# Create a list to hold recommendations and explanations\n",
    "recommendations_list = []\n",
    "\n",
    "# Prepare the detailed explanation for each recommended title\n",
    "for idx, title in enumerate(top_5_titles):\n",
    "    explanation_list = []\n",
    "    \n",
    "    # Loop through each feature to generate explanations\n",
    "    for i, feature in enumerate(features.columns):\n",
    "        person_value = person_data[feature].values[0]\n",
    "        importance = importance_vals[i]\n",
    "        \n",
    "        # Check if it's the 'Reccomended_Type_Encoded' column to decode its original value\n",
    "        if feature == 'Reccomended_Type_Encoded':\n",
    "            explanation_list.append(f\"{Name_input}'s recommended type was '{person_recommended_type}', \"\n",
    "                                    f\"and this feature had an importance score of {importance:.4f}.\")\n",
    "        elif importance > 0.01:  # Only include features with notable importance\n",
    "            explanation_list.append(f\"{Name_input}'s value on the survey for '{feature}' was {person_value}, \"\n",
    "                                    f\"and this feature was important with an importance score of {importance:.4f}.\")\n",
    "    \n",
    "    # Add the recommendation and explanation to the list\n",
    "    recommendations_list.append({'Recommendation': title, 'Explanation': '\\n'.join(explanation_list)})\n",
    "\n",
    "# Convert the list to a DataFrame using concat\n",
    "recommendations_df = pd.concat([pd.DataFrame([rec]) for rec in recommendations_list], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18a9efa-f5b3-4e67-9cce-adc10e86387c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Explanation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3628\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3629\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Explanation'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5x/51cr7tt568l_xbv9_p2b91y40000gn/T/ipykernel_3357/608579548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# First, split the 'Explanation' column by '\\n' to create lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecommendations_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Explanation_Split'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommendations_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Explanation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Use explode to split each explanation into a separate row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrecommendations_df_exploded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecommendations_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Explanation_Split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3505\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3506\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3629\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3631\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3632\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3633\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Explanation'"
     ]
    }
   ],
   "source": [
    "# First, split the 'Explanation' column by '\\n' to create lists\n",
    "recommendations_df['Explanation_Split'] = recommendations_df['Explanation'].str.split('\\n')\n",
    "\n",
    "# Use explode to split each explanation into a separate row\n",
    "recommendations_df_exploded = recommendations_df.explode('Explanation_Split')\n",
    "\n",
    "# Rename the column for better clarity\n",
    "recommendations_df_exploded.rename(columns={'Explanation_Split': 'Explanation_Part'}, inplace=True)\n",
    "\n",
    "# Print model accuracy and F1 score\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Model F1 Score: {f1:.4f}\")\n",
    "\n",
    "recommendations_df_exploded = recommendations_df_exploded.drop(columns=['Explanation'])\n",
    "recommendations_df_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bfd7d4d-c933-44aa-a2a4-0f693f3ae42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the index of the recommendation you'd like to reject (0-4):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You rejected: Culture of Honor\n",
      "Updated Recommendations with Dislike feedback:\n",
      "                                      Recommendation  Strength  Disliked\n",
      "0                                   Culture of Honor  0.650000      True\n",
      "1                                   Girls Gone Bible  0.120833     False\n",
      "2                                 Rich Dad, Poor Dad  0.108500     False\n",
      "3      Blink: The Power of Thinking Without Thinking  0.100667     False\n",
      "4  How I climbed a 3,000- foot vertical cliff -- ...  0.010000     False\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/5x/51cr7tt568l_xbv9_p2b91y40000gn/T/ipykernel_3357/3258920881.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m models = {\n\u001b[1;32m     19\u001b[0m     \u001b[0;34m'RandomForest'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;34m'LogisticRegression'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;34m'GradientBoosting'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;34m'SVC'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "# User inputs the index of the recommendation they'd like to reject\n",
    "rejected_index = int(input(\"Enter the index of the recommendation you'd like to reject (0-4): \"))\n",
    "rejected_recommendation = top_5_titles[rejected_index]\n",
    "print(f\"You rejected: {rejected_recommendation}\")\n",
    "\n",
    "# Create a DataFrame with recommendations and include a column indicating dislikes\n",
    "recommendations_df = pd.DataFrame({\n",
    "    'Recommendation': top_5_titles,\n",
    "    'Strength': proba_person[0][top_5_indices],\n",
    "    'Disliked': [title == rejected_recommendation for title in top_5_titles]  # Add 'Disliked' column\n",
    "})\n",
    "\n",
    "# Display the updated DataFrame with the Disliked column before model selection\n",
    "print(\"Updated Recommendations with Dislike feedback:\")\n",
    "print(recommendations_df)\n",
    "\n",
    "# Define a list of models to compare\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'SVC': SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Store model accuracies\n",
    "model_accuracies = {}\n",
    "\n",
    "# Train each model and calculate accuracy\n",
    "for model_name, model in models.items():\n",
    "    # Fit the model on the entire dataset\n",
    "    model.fit(features_standardized, target)\n",
    "    \n",
    "    # Get predictions and calculate accuracy\n",
    "    predictions = model.predict(features_standardized)\n",
    "    accuracy = accuracy_score(target, predictions)\n",
    "    model_accuracies[model_name] = accuracy\n",
    "\n",
    "# Select the best model based on accuracy\n",
    "best_model_name = max(model_accuracies, key=model_accuracies.get)\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "print(f\"Best model selected: {best_model_name} with accuracy: {model_accuracies[best_model_name]:.4f}\")\n",
    "\n",
    "# Re-run predictions with the best model\n",
    "proba_person = best_model.predict_proba(X_person_standardized)\n",
    "\n",
    "# Get the top recommendations\n",
    "all_titles = target.unique()\n",
    "\n",
    "# Sort the remaining valid recommendations by their probabilities\n",
    "top_5_indices = np.argsort(proba_person[0])[-5:][::-1]\n",
    "new_top_5_titles = all_titles[top_5_indices]\n",
    "\n",
    "# Update the DataFrame with new top recommendations, retaining the 'Disliked' column\n",
    "new_recommendations_df = pd.DataFrame({\n",
    "    'Recommendation': new_top_5_titles,\n",
    "    'Strength': proba_person[0][top_5_indices],\n",
    "    'Disliked': [title == rejected_recommendation for title in new_top_5_titles]  # Carry over 'Disliked' feedback\n",
    "})\n",
    "\n",
    "# Display the updated DataFrame with new recommendations and feedback\n",
    "print(\"New Top 5 Recommendations (after rejection):\")\n",
    "new_recommendations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf31445-6c87-49ca-8374-2347f05e695e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
